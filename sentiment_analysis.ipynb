{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEwYgJ9InIhOARkY/SBdBP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryamyazdi/snappfood-sentiment-analysis/blob/master/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hazm as hz\n",
        "from finglish import f2p\n",
        "import itertools\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import torch\n",
        "import gensim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "gpu_enable = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if gpu_enable else 'cpu')"
      ],
      "metadata": {
        "id": "Pwsrwkln6Id6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./data/train.csv', sep='\\t', index_col=0)\n",
        "train_data = (df.head(n=300)).drop(axis=1, columns='label')\n",
        "\n",
        "#Preprocessing\n",
        "def fixup(x):\n",
        "    x = x.replace('\\u200c', '').replace('\\xa0','').replace('\\r\\n',' ').replace('|',' ')\n",
        "    return x\n",
        "\n",
        "normalizer = hz.Normalizer()\n",
        "\n",
        "def my_tokenizer(text):\n",
        "  text = re.sub(r\"[\\{\\}\\؛\\*\\=\\-\\+\\/\\n\\(\\)]\",\" \",str(text))\n",
        "  text = re.sub(\"[ ]+\",\" \",text)\n",
        "  text = re.sub(\"\\!+\",\"!\",text)\n",
        "  text = re.sub(\"[؟]+\",\"؟\",text)\n",
        "  text = re.sub(\"\\?+\",\"?\",text)\n",
        "  text = re.sub(\"[.]+\",\"\",text)\n",
        "  text = re.sub(\"[،]+\",\"\",text)\n",
        "  if(bool(re.match('^[a-zA-Z]',text))==True):\n",
        "    text=f2p(text)\n",
        "  for c in \"..آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهیئ\":\n",
        "    text = re.sub(f\"[{c}]+\", c, text)\n",
        "  text = fixup(normalizer.normalize(text))\n",
        "  words = []\n",
        "  words.append(hz.word_tokenize(text))\n",
        "  return words\n",
        "\n",
        "nested_train_data = train_data['comment'].apply(my_tokenizer)\n",
        "train_data['comment'] = list(itertools.chain(*nested_train_data))"
      ],
      "metadata": {
        "id": "9PRU3gvS6GsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "H8yzerAiOWyX",
        "outputId": "8efadd4a-a9b9-457f-a2e7-b7c8eb621f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               comment  label_id\n",
              "0    [واقعا, حیف, وقت, که, بنویسم, سرویس, دهیتون, ش...         1\n",
              "1    [قرار, بود, ۱, ساعته, برسه, ولی, نیم, ساعت, زو...         0\n",
              "2    [قیمت, این, مدل, اصلا, با, کیفیتش, سازگاری, ند...         1\n",
              "3    [عالی, بود, همه, چه, درست, و, به, اندازه, و, ک...         0\n",
              "4                  [شیرینی, وانیلی, فقط, یک, مدل, بود]         0\n",
              "..                                                 ...       ...\n",
              "295  [فقط, ساندویچ, سرد, شده_بود, با, اینکه, ده, دق...         0\n",
              "296  [برگش, خیلی, عالی, بود, ولی, کباب, لقمهاش, بد,...         1\n",
              "297  [قبلا, خیلی, خوب, بود, ولی, نمیدونم, چرا, اینق...         1\n",
              "298           [زرشک, پلو, با, مرغ, با, بوی, بسیار, بد]         1\n",
              "299  [پک, دیزی, با, این, که, تو, تخفیف, ۴۰, درصدی, ...         0\n",
              "\n",
              "[300 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9e9eab0-4e27-44f8-82b1-892cafd59771\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[واقعا, حیف, وقت, که, بنویسم, سرویس, دهیتون, ش...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[قرار, بود, ۱, ساعته, برسه, ولی, نیم, ساعت, زو...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[قیمت, این, مدل, اصلا, با, کیفیتش, سازگاری, ند...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[عالی, بود, همه, چه, درست, و, به, اندازه, و, ک...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[شیرینی, وانیلی, فقط, یک, مدل, بود]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>[فقط, ساندویچ, سرد, شده_بود, با, اینکه, ده, دق...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>[برگش, خیلی, عالی, بود, ولی, کباب, لقمهاش, بد,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>[قبلا, خیلی, خوب, بود, ولی, نمیدونم, چرا, اینق...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>[زرشک, پلو, با, مرغ, با, بوی, بسیار, بد]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>[پک, دیزی, با, این, که, تو, تخفیف, ۴۰, درصدی, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9e9eab0-4e27-44f8-82b1-892cafd59771')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9e9eab0-4e27-44f8-82b1-892cafd59771 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9e9eab0-4e27-44f8-82b1-892cafd59771');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Some statistical info\n",
        "words_count = train_data['comment'].apply(len)\n",
        "\n",
        "print('Min length =', words_count.min())\n",
        "print('Max length =', words_count.max())\n",
        "print('Mean = {:.2f}'.format(words_count.mean()))\n",
        "print('Std  = {:.2f}'.format(words_count.std()))\n",
        "print('mean + 2 * sigma = {:.2f}'.format(words_count.mean() + 2.0 * words_count.std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iALvXoOoXyan",
        "outputId": "ff4386f2-282e-4921-cfcf-9ddde6b364ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min length = 4\n",
            "Max length = 124\n",
            "Mean = 16.78\n",
            "Std  = 15.29\n",
            "mean + 2 * sigma = 47.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 32\n",
        "PAD = '<pad>'\n",
        "\n",
        "#Make all tokens the same length\n",
        "def padding_and_trimming(tokens):\n",
        "  if len(tokens) < max_len:\n",
        "      num_pads = max_len - len(tokens)\n",
        "      tokens = [PAD] * num_pads + tokens\n",
        "  elif len(tokens) > max_len:\n",
        "      tokens = tokens[:max_len]\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "s0DmRlfLYEpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['comment'] = train_data['comment'].apply(padding_and_trimming)"
      ],
      "metadata": {
        "id": "SwPpmznjrBFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget 'http://vectors.nlpl.eu/repository/20/61.zip' -O './w2vec.zip'\n",
        "!unzip ./w2vec.zip -d ./w2vec\n",
        "\n",
        "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('./w2vec/model.txt', binary=False, unicode_errors='replace')\n",
        "w2v_weights = torch.FloatTensor(w2v_model.vectors)"
      ],
      "metadata": {
        "id": "k3t1VKMRr0dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(nn.Module):\n",
        "  def __init__(self, hidden_size, batch_size, layers_count):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.batch_size = batch_size\n",
        "    self.layers_count = layers_count\n",
        "\n",
        "    self.embedding = nn.Embedding.from_pretrained(w2v_weights)\n",
        "    self.lstm = nn.LSTM(100, hidden_size, layers_count, bidirectional=True, batch_first=True)\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Linear(2*hidden_size, 100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100, 2)\n",
        "    )\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    h = torch.autograd.Variable(torch.zeros((2*self.layers_count, self.batch_size, self.hidden_size)).to(device))\n",
        "    c = torch.autograd.Variable(torch.zeros((2*self.layers_count, self.batch_size, self.hidden_size)).to(device))\n",
        "    return h, c\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x, self.hidden = self.lstm(x, self.hidden)\n",
        "    x = x.permute(1, 0, 2).detach()\n",
        "    x = self.classifier_layer(x[-1])\n",
        "    return x"
      ],
      "metadata": {
        "id": "f8j53D5jslxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "lstm_model = LSTMClassifier(hidden_size=512, batch_size=BATCH_SIZE, layers_count=1)\n",
        "\n",
        "if gpu_enable:\n",
        "  lstm_model = lstm_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if gpu_enable:\n",
        "  criterion = criterion.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.01, betas=(0.7, 0.99))\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.975)"
      ],
      "metadata": {
        "id": "OTtH9hQBtiMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PAD = '<pad>'\n",
        "UNK = '<unk>'\n",
        "\n",
        "class TDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.X_train = dataset['comment']\n",
        "        self.y_train = dataset['label_id']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_train)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        vectors = []\n",
        "        for token in self.X_train[index]:\n",
        "          if token == PAD:\n",
        "            vectors.append(1)\n",
        "            continue\n",
        "          try:\n",
        "            vectors.append(w2v_model.vocab[token].index)\n",
        "          except KeyError:\n",
        "            vectors.append(2)\n",
        "        return torch.tensor(vectors), torch.tensor(self.y_train[index])\n",
        "\n",
        "\n",
        "dataset = TDataset(train_data)"
      ],
      "metadata": {
        "id": "0o-j5J1HtzK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "lstm_model.train()\n",
        "\n",
        "losses = []\n",
        "for epoch in range(5):\n",
        "  total_loss = 0\n",
        "  for i, (inputs, targets) in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    outputs = lstm_model(inputs)\n",
        "    \n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    scheduler.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/5 : step {i + 1}/{len(dataset) // BATCH_SIZE}, loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "MfE9j5nQtzrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}